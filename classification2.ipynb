{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist.data.shape\n",
    "\n",
    "X, y = mnist.data, mnist.target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape((28, 28))\n",
    "plt.imshow(some_digit_image, cmap=mpl.cm.binary, interpolation='nearest')\n",
    "plt.axis('off')\n",
    "print(y[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(y.dtype)\n",
    "y = y.astype(np.int)\n",
    "print(y.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "y_train_5 = (y_train == 5) # True for all 5s, False for all other digits.\n",
    "y_test_5 = (y_test == 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "sgd_clf.predict([some_digit])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train_5[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train_5[test_index]\n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct / len(y_pred)) #"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring='accuracy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 当用一个随机分类器\n",
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "That’s right, it has over 90% accuracy! This is simply because only about 10% of the images are 5s, so if you always guess that an image is not a 5, you will be right about 90% of the time. Beats Nostradamus.\n",
    "This demonstrates why accuracy is generally not the preferred performance measure for classifiers, especially when you are dealing with skewed datasets (i.e., when some classes are much more frequent than others).\n",
    "\n",
    "#### from sklearn.model_selection import cross_val_predict\n",
    "Generate cross-validated estimates for each input data point\n",
    "\n",
    "The data is split according to the cv parameter. Each sample belongs to exactly one test set, and its prediction is computed with an estimator fitted on the corresponding training set.\n",
    "\n",
    "Passing these predictions into an evaluation metric may not be a valid way to measure generalization performance. Results can differ from cross_validate and cross_val_score unless all tests sets have equal size and the metric decomposes over samples."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, n_jobs=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# a numpy array\n",
    "y_train_pred\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A much better way to evaluate the performance of a classifier is to look at the confusion matrix.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "confusion_matrix(y_train_5, y_train_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print(precision_score(y_train_5, y_train_pred))\n",
    "print(recall_score(y_train_5, y_train_pred))\n",
    "print(f1_score(y_train_5, y_train_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. The F1 score favors classifiers that have similar precision and recall\n",
    "2. Unfortunately, you can’t have it both ways: increasing precision reduces recall, and vice versa. This is called the precision/recall tradeoff.\n",
    "\n",
    "\n",
    "可以试着调整threshold来改变precision和recall的偏好，sklearn不让你直接设置threhold. The SGDClassifier uses a threshold equal to 0, so the previous code returns the same result as the predict() method (i.e., True). Let’s raise the threshold:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_scores = sgd_clf.decision_function([some_digit])\n",
    "y_scores\n",
    "threshold = 0\n",
    "y_some_digit_threhold = (y_scores > threshold)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,\n",
    "                             method=\"decision_function\")\n",
    "print(y_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
    "\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    # highlight the threshold, add the legend, axis label and grid\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(thresholds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You may wonder why the precision curve is bumpier than the recall curve\n",
    " in Figure 3-4. The reason is that precision may sometimes go down when\n",
    "  you raise the threshold (although in general it will go up). To\n",
    "  understand why, look back at Figure 3-3 and notice what happens when\n",
    "  you start from the central threshold and move it just one digit to the\n",
    "   right: precision goes from 4/5 (80%) down to 3/4 (75%). On the other\n",
    "    hand, recall can only go down when the thres‐ hold is increased,\n",
    "    which explains why its curve looks smooth."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "plot_precision_recall_curve(sgd_clf, X_train, y_train_5)\n",
    "\n",
    "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]\n",
    "y_train_pred_90 = (y_scores >= threshold_90_precision)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "precision_score(y_train_5, y_train_pred_90)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "recall_score(y_train_5, y_train_pred_90)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    # dashed diagonal [...] # Add axis labels and grid\n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once again there is a tradeoff: the higher the recall (TPR), the more false\n",
    " positives (FPR) the classifier produces. The dotted line represents the ROC\n",
    " curve of a purely random classifier; a good classifier stays as far away\n",
    " from that line as possible (toward the top-left corner).\n",
    "\n",
    "Since the ROC curve is so similar to the precision/recall (or PR) curve, you\n",
    "may wonder how to decide which one to use. As a rule of thumb, you should\n",
    " prefer the PR curve whenever the positive class is rare or when you care more\n",
    "  about the false positives than the false negatives, and the ROC curve\n",
    "  otherwise. For example, looking at the previous ROC curve (and the ROC AUC\n",
    "   score), you may think that the classifier is really good. But this is mostly\n",
    "    because there are few positives (5s) compared to the negatives (non-5s).\n",
    "     In contrast, the PR curve makes it clear that the classifier has room for\n",
    "      improvement (the curve could be closer to the top- right corner)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_train_5, y_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,\n",
    "method=\"predict_proba\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "y_scores_forest = y_probas_forest[:, 1] # score = proba of positive class\n",
    "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5,y_scores_forest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(fpr, tpr, \"b:\", label=\"SGD\")\n",
    "plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "roc_auc_score(y_train_5, y_scores_forest)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multiclass Classification\n",
    "\n",
    "One-vs-All or one-vs-one"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sgd_clf.fit(X_train, y_train)\n",
    "sgd_clf.predict([some_digit])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sgd是默认one-vs-all\n",
    "some_digit_score = sgd_clf.decision_function([some_digit])\n",
    "some_digit_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[5860,   63,    0,    0,    0,    0,    0,    0,    0,    0],\n       [6675,   67,    0,    0,    0,    0,    0,    0,    0,    0],\n       [5932,   26,    0,    0,    0,    0,    0,    0,    0,    0],\n       [5913,  218,    0,    0,    0,    0,    0,    0,    0,    0],\n       [5821,   21,    0,    0,    0,    0,    0,    0,    0,    0],\n       [1891, 3530,    0,    0,    0,    0,    0,    0,    0,    0],\n       [5796,  122,    0,    0,    0,    0,    0,    0,    0,    0],\n       [6251,   14,    0,    0,    0,    0,    0,    0,    0,    0],\n       [5741,  110,    0,    0,    0,    0,    0,    0,    0,    0],\n       [5903,   46,    0,    0,    0,    0,    0,    0,    0,    0]])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "conf_mx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 288x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi label\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "KNeighborsClassifier()"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "y_train_large = (y_train >= 7)\n",
    "y_train_odd = (y_train % 2 == 1)\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[False,  True]])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf.predict([some_digit])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}